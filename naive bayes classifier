#naive bayes classifier

import random
import codecs
data=[]
with codecs.open('terrorist corpus.txt','r',encoding='utf-8', errors='ignore') as f:
    for line in f:
             data.append((line,'terrorist'))
with codecs.open('twitter corpus.txt','r',encoding='utf-8', errors='ignore') as f:
    for line in f:
             data.append((line,'twitter'))
random.shuffle(data)

def train_and_test_data(data_):
    filesize = int(0.7 * len(data_))
    # train-set:test-set=7:3
    train_data_ = [each[0] for each in data_[:filesize]]
    train_target_ = [each[1] for each in data_[:filesize]]

    test_data_ = [each[0] for each in data_[filesize:]]
    test_target_ = [each[1] for each in data_[filesize:]]

    return train_data_, train_target_, test_data_, test_target_

train_data, train_target, test_data, test_target = train_and_test_data(data)
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import BernoulliNB

#use MultinomialNB and BernoulliNB models

nbc = Pipeline([
    ('vect', TfidfVectorizer(

    )),
    ('clf', MultinomialNB(alpha=1.0)),
])
nbc.fit(train_data, train_target)   
predict = nbc.predict(test_data) 
count = 0                                      
for left , right in zip(predict, test_target):
      if left == right:
            count += 1
count=float(count)
print count/len(test_target)
nbc_1= Pipeline([
    ('vect', TfidfVectorizer(

    )),
    ('clf', BernoulliNB(alpha=0.1)),
])
nbc_1.fit(train_data, train_target)
predict = nbc_1.predict(test_data)  
count = 0                                    
for left , right in zip(predict, test_target):
      if left == right:
            count += 1
count=float(count)
print count/len(test_target)
