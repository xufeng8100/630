from functools import partial
from sys import maxint
import sys
import time
import twitter
from urllib2 import URLError
from httplib import BadStatusLine
import json
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import tweepy
from tweepy import OAuthHandler
import json
import time
import pickle

auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_secret)
api = tweepy.API(auth)
def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,
                               friends_limit=maxint, followers_limit=maxint):
     assert (screen_name != None) != (user_id != None), \
     "Must have screen_name or user_id, but not both"

     get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids,
                               count=5000)
     get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids,
                               count=5000)
     friends_ids, followers_ids = [], []
     for twitter_api_func, limit, ids, label in [
                     [get_friends_ids, friends_limit, friends_ids, "friends"],
                     [get_followers_ids, followers_limit, followers_ids, "followers"]
                  ]:
         if limit == 0: continue
         cursor = -1
         while cursor != 0:
# Use make_twitter_request via the partially bound callable...
            if screen_name:
                response = twitter_api_func(screen_name=screen_name, cursor=cursor)
            else: # user_id
                response = twitter_api_func(user_id=user_id, cursor=cursor)
            if response is not None:
                ids += response['ids']
                cursor = response['next_cursor']
            print >> sys.stderr, 'Fetched {0} total {1} ids for {2}'.format(len(ids),
                                                         label, (user_id or screen_name))
# XXX: You may want to store data during each iteration to provide an
# an additional layer of protection from exceptional circumstances
            if len(ids) >= limit or response is None:
                break
# Do something useful with the IDs, like store them to disk...
     return friends_ids[:friends_limit], followers_ids[:followers_limit]
def get_user_profile(twitter_api, screen_names=None, user_ids=None):
# Must have either screen_name or user_id (logical xor)
     assert (screen_names != None) != (user_ids != None), \
"Must have screen_names or user_ids, but not both"
     items_to_info = {}
     items = screen_names or user_ids
     while len(items) > 0:
        items_str = ','.join([str(item) for item in items[:100]])
        items = items[100:]
        if screen_names:
           response = make_twitter_request(twitter_api.users.lookup,
                                         screen_name=items_str)
        else: # user_ids
           response = make_twitter_request(twitter_api.users.lookup,
                                         user_id=items_str)
        for user_info in response:
           if screen_names:
              items_to_info[user_info['screen_name']] = user_info
           else: # user_ids
              items_to_info[user_info['id']] = user_info
     return items_to_info

name= ["uyghurproject", "UyghurCongress", "fahriu89", "pl4et", "SarjaniUyghur2", "Muslim4Mchina", "musuluyghur",
        "iamgul8", "Salih_Hudayar", "parlabest", "UHRP_Chinese", "VoiceUyghur", "EastTurkDaily", "SultanUyghur",
        "VoiceOfUyghur", "ismaelan", "AbdugheniSabit"]

friends_ids=[]
followers_ids=[]
for screen_name in name:
     friends_id, followers_id = get_friends_followers_ids(twitter_api,
                 screen_name=screen_name,friends_limit=10000,followers_limit=10000)
     friends_ids +=friends_id
     followers_ids +=followers_id
friends_ids=list(set(friends_ids))
followers_ids=list(set(followers_ids))
jsObj=[]
fileObject = open('friends_ids.json', 'w')
jsObj= json.dumps(friends_ids)
fileObject.write(jsObj)
fileObject.close()
jsObj=[]
fileObject = open('followers_ids.json', 'w')
jsObj= json.dumps(followers_ids)
fileObject.write(jsObj)
fileObject.close()
friends_fowllowers_ids=friends_ids+followers_ids
friends_fowllowers_ids=list(set(friends_fowllowers_ids))
jsObj=[]
fileObject = open('friends_fowllowers_ids.json', 'w')
jsObj= json.dumps(friends_fowllowers_ids)
fileObject.write(jsObj)
fileObject.close()
friends_fowllowers_idss=friends_fowllowers_ids[:]
a=0
for id in friends_fowllowers_ids:
     tweet = harvest_user_timeline(twitter_api, user_id=id,max_results=1)
     a += 1
     if len(tweet)==0:
        friends_fowllowers_idss.remove(id)
     time.sleep(0.3)
     print a
friends_fowllowers_ids=friends_fowllowers_idss
fileObject = open('friends_fowllowers_ids.json', 'w')
jsObj= json.dumps(friends_fowllowers_ids)
fileObject.write(jsObj)
fileObject.close()
s = get_user_profile(twitter_api, user_ids=[])
df1 = pd.DataFrame(s)
a=0
for id in friends_fowllowers_ids:
    s=get_user_profile(twitter_api, user_ids=[id])
    df2=pd.DataFrame(s)
    df1 = pd.concat([df1, df2], axis=1)
    a +=1
    print a
df1.to_csv('friends_fowllowers_profile.csv')

friends_fowllowers_ids_1=friends_fowllowers_ids[:300]
per=0
supporter_ids_per_1=[]
supporter_ids_nums_1=[]
a=0
for id in friends_fowllowers_ids_1:
     nums=0
     b=0
     for tweet in tweepy.Cursor(api.user_timeline,id=id).items():
         b +=1
         num = predict_one(tweet.text)
         nums +=num
     per=nums/b
     if per>0:
        supporter_ids_per_1.append((id,per))
        supporter_ids_nums_1.append((id,nums))
     a += 1
     print(a)
f1 = open("supporter_ids_nums_1","wb")
pickle.dump(supporter_ids_nums_1, f1)
f1.close()
f1 = open("supporter_ids_per_1","wb")
pickle.dump(supporter_ids_per_1, f1)
f1.close()

G = nx.DiGraph()
for id in friends_fowllowers_ids_1:
           G.add_node(id)
a=0
for id in friends_fowllowers_ids_1:
    friendslist = api.friends_ids(id=id)
    followersidslist = api.followers_ids(id=id)
    if set(friendslist).intersection(set(friends_fowllowers_ids_1)) != set():
        for s in set(friendslist).intersection(set(friends_fowllowers_ids_1)):
             G.add_edge(id, s)
    if set(followersidslist).intersection(set(friends_fowllowers_ids_1)) != set():
        for s in set(followersidslist).intersection(set(friends_fowllowers_ids_1)):
             G.add_edge(s, id)
    time.sleep(60)
    a+=1
    print(a)
    d1 = dict(supporter_ids_per_1)
    d2 = dict(supporter_ids_nums_1)
    pos = nx.spring_layout(G)
    for node in G.node:
        nx.draw_networkx_nodes(G, pos, nodelist=[node], node_size=d2[node] / 10, node_color='r', alpha=d1[node])
    pos = nx.get_node_attributes(G, 'pos')
    nx.write_gpickle(G, "friends_fowllowers_ids.gpickle")
